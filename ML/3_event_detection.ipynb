{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seismic event detection\n",
    "\n",
    "## Problem statement\n",
    "\n",
    "In this tutorial, we will analyse timeseries data recorded by an acoustic sensor in a lab friction experiment (courtesy of Evangelos Korkolis, Utrecht University). During this experiment, the sample exhibited stick-slip deformation, the laboratory-scale analogue of earthquakes. Just prior to a major stick-slip event, the sample would start to emit tiny acoustic emissions (\"foreshocks\"), which are detected by piezo-electric sensors (\"seismometers\") installed around the sample. Some of these acoustic emissions are clearly visible in the timeseries, whereas others occur near the level of the noise. Classical methods (such as ST/LT thresholding) don't perform well on the smaller acoustic emissions, and so we will use machine learning to lower the automatic detection threshold.\n",
    "\n",
    "## Data description\n",
    "\n",
    "The training/testing data are small, randomly selected segments of acoustic timeseries data, each segment consisting of 1024 datapoints. Associated with each segment is a binary label that is `0` when the segment only contains noise, and is `1` when the segment contains one or more acoustic emissions. The training and testing data are shuffled, so that there is no temporal relation between the segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    with gzip.GzipFile(\"AE_data.tar.gz\", \"r\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data[\"train_data\"], data[\"train_labels\"], data[\"test_data\"], data[\"test_labels\"]\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "train_signals, train_labels, test_signals, test_labels = load_data()\n",
    "\n",
    "# For convolutional layers, an additional dimension needs to be added\n",
    "train_signals = np.expand_dims(train_signals, 2)\n",
    "test_signals = np.expand_dims(test_signals, 2)\n",
    "\n",
    "print(train_signals.shape, test_signals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation\n",
    "\n",
    "As always, it's good to first have a look at some examples from the training data set. The code below plots \"event\" signals on the left, and \"noise\" signals on the right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select training signals of events\n",
    "events = (train_labels == 1)\n",
    "event_signals = train_signals[events][:5].reshape((5, -1))\n",
    "\n",
    "# Select training signals of noise (no events)\n",
    "noise_signals = train_signals[~events][:5].reshape((5, -1))\n",
    "\n",
    "# Plot 5 examples of events and noise\n",
    "for i in range(5):\n",
    "    # Events\n",
    "    plt.subplot(5, 2, 1+2*i)\n",
    "    if i == 0:\n",
    "        plt.title(\"Events\")\n",
    "    plt.plot(event_signals[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Noise\n",
    "    plt.subplot(5, 2, 2+2*i)\n",
    "    if i == 0:\n",
    "        plt.title(\"Noise\")\n",
    "    plt.plot(noise_signals[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction\n",
    "\n",
    "Your task will be to construct a neural network (dense, convolutional, or a combination of both) that takes a 1D timeseries of size 1024 as an input, and outputs a single scalar between 0 and 1 (0 corresponds to \"no event\", 1 corresponds to \"yes event\"). In the code below, the output layer is given, everything else is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras default initialiser = glorot_uniform\n",
    "# A better initialiser for ReLU activations = he_normal\n",
    "initializer = \"he_normal\"\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Insert your architecture here\n",
    "    # Examples of layers you could include:\n",
    "    #\n",
    "    # Fully-connected:  keras.layers.Dense(128, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "    # Convolutional:    keras.layers.Conv1D(64, kernel_size=5, activation=tf.nn.relu, kernel_initializer=initializer, padding=\"same\")\n",
    "    # Max pooling:      keras.layers.MaxPooling1D()\n",
    "    # Flattening:       keras.layers.Flatten()\n",
    "    #\n",
    "    \n",
    "    # Output layer: 1 output, sigmoid activation\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid, kernel_initializer=\"glorot_normal\")\n",
    "])\n",
    "\n",
    "# Compile and print a summary\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Make sure to experiment with different training durations (`epochs`) to ensure that the model was trained long enough, but not too long..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_signals, \n",
    "    train_labels, \n",
    "    validation_data=(test_signals, test_labels),\n",
    "    verbose=1,\n",
    "    epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy and visualisation\n",
    "\n",
    "The worst-case performance of the model would be a 50-50 guess (yes/no event), which would give a test accuracy of 50% (since events and noise are evenly represented in the test set). So our trained model should perform significantly better than 50% to be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_signals, test_labels)\n",
    "print(\"Test accuracy: %.4f\" % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to see what this accuracy score looks like, we can plot a number of seismograms and colour them according to the accuracy of the prediction (green = correct, red = wrong)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_signals)\n",
    "predictions = np.round(predictions).astype(int)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Plot 70 examples of events and noise\n",
    "for i in range(10):\n",
    "    for j in range(7):\n",
    "        n = 7*i + j\n",
    "        # Events\n",
    "        plt.subplot(10, 7, 1+n)\n",
    "        if predictions[n] == test_labels[n]:\n",
    "            colour = \"g\"\n",
    "        else:\n",
    "            colour = \"r\"\n",
    "        plt.plot(test_signals[n], c=colour)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
